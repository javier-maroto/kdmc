\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


% Added packages
\usepackage{cite}  
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{positioning}


\newcommand{\pf}[1]{{\textcolor{orange}{PF: {#1}}}}
%\newcommand{\pf}[1]{} %cuncomment this one, and comment the previous line to remove all comments...

% Latex math commands
\newcommand{\Ls}{\mathcal{L}}
\def\sP{{\mathbb{P}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

%\title{SafeAMC: Adversarial training for robust modulation recognition models}

%\name{Javier Maroto\thanks{This work has been sponsored by armasuisse Science and Technology with the project ROBIN (project code Aramis 047-22).}$^{\star}$ \qquad Gérôme Bovet$^{\dagger}$ \qquad Pascal Frossard$^{\star}$}
  
%\address{$^{\star}$ EPFL, Switzerland \\
%  $^{\dagger}$armasuisse Science\&Technology, Cyber-Defence Campus, Switzerland}
  
\title{Improving modulation classification by distilling maximum likelihood \pf{Maximum Likelihood Distillation for Robust Modulation Classification}
\thanks{This work has been sponsored by armasuisse Science and Technology under the project ARNO (project code ARAMIS 047-22).}
}

\author{\IEEEauthorblockN{Javier Maroto}
\IEEEauthorblockA{\textit{Signal Processing Laboratory (LTS4)} \\ \textit{EPFL, Switzerland}}
\and
\IEEEauthorblockN{Gérôme Bovet}
\IEEEauthorblockA{\textit{armasuisse Science\&Technology} \\
\textit{Cyber-Defence Campus, Switzerland}}
\and
\IEEEauthorblockN{Pascal Frossard}
\IEEEauthorblockA{\textit{Signal Processing Laboratory (LTS4)} \\ \textit{EPFL, Switzerland}}}


\begin{document}
\maketitle

\begin{abstract}
Deep Neural Networks are being extensively used in communication systems and Automatic Modulation Classification (AMC) in particular. However, they are very susceptible to small adversarial perturbations that are carefully crafted to change the network decision. In this work, we build on knowledge distillation ideas and adversarial training in order to build more robust AMC systems. We first outline the importance of the quality of the training data in terms of accuracy and robustness of the model. We then propose to use the Maximum Likelihood function, which could solve the AMC problem in offline settings, to generate better training labels. Those teach the model to be uncertain in challenging conditions, which permits to increase the standard accuracy, as well as the robustness of the model when combined with adversarial training. \pf{add some quantitative notes or more precise information about the actual results.}\pf{recall contributions/benefits or add general perspectives about the potential of the proposal: so what? why is that a cool idea, a cool paper?} \pf{re-check the full paragraph} 
\end{abstract}

\begin{IEEEkeywords}
Neural networks, robustness, Maximum Likelihood, knowledge distillation, automatic modulation classification
\end{IEEEkeywords}

\section{Introduction}

% AMC, deep learning is being used. Different solutions
Communication systems often require the receiver to recognize the modulation scheme that has been used to encode the transmitted signals. This is often refered as Automatic Modulation Classification (AMC) in applications ranging from detecting daily radio stations and managing spectrum resources, to eavesdropping and interfering with radio communications. The AMC task can be formaulated as a Maximum likelihood (ML) estimation problem \cite{huan1995likelihood,dobre2007survey,hameed2009likelihood}, by computing the maximum of the likelihood function of the received signal with all possible modulations. Even if the solution is Bayes-optimal, sub-optimal approximations are used in practice \cite{dobre2007survey,Hameed_Dobre_Popescu_2009} because ML requires prior knowledge of the channel characteristics and is computationally complex to solve in realtime.

Deep learning \cite{goodfellow2016deep} has been proposed as a better solution for AMC as neural networks are relatively fast at inference time, adaptable to any channel characteristics, and their performance scales well with large quantities of data. Inspired by success in speech recognition, some works \cite{Rajendran_Meert_Giustiniano_Lenders_Pollin_2018,Guo_Jiang_Wu_Zhou_2020} propose architectures based on long short-term memory networks (LSTMs) \cite{Hochreiter_Schmidhuber_1997}. Other works \cite{OShea_Corgan_Clancy_2016,West_OShea_2017,Sadeghi_Larsson_2019} employ convolutional neural networks (CNNs) \cite{Krizhevsky_Sutskever_Hinton_2017} instead, which have been highly successful in computer vision tasks. Particularly, the authors in \cite{OShea_Roy_Clancy_2018} use a model based on the ResNet architecture \cite{Szegedy_Ioffe_Vanhoucke_Alemi_2016}, that outperforms all other CNN architectures. Other works use neural architecture search (NAS) \cite{ahmadi2008modulation,dai2019multi,perenda2021evolutionary} to trade off performance with computational speed. Even though neural networks are currently the main and most effective method that tackles the AMC problem \cite{OShea_Roy_Clancy_2018}, they are very susceptible to adversarial perturbations, which compromises the security of the system against malicious attacks  \cite{Szegedy_Zaremba_Sutskever_Bruna_Erhan_Goodfellow_Fergus_2014, moosavi2017universal,Sadeghi_Larsson_2019,Lin_Zhao_2020,Flowers_Buehrer_Headley_2019, maroto2021benefits}. \pf{that one can be shortened a bit if needed.}

% With the emergence of deep learning \cite{goodfellow2016deep}, neural networks made their way into AMC, and are currently the main and most effective method that tackles this problem \cite{OShea_Roy_Clancy_2018}. Compared with previous methods, like feature extraction \cite{xie2008efficient,zhou2013design,zhang2017wireless} or maximum likelihood functions \cite{huan1995likelihood,dobre2007survey,hameed2009likelihood}, neural networks are relatively fast, adaptable to any channel characteristics, and their performance scales well with high quantities of data.

% Effect of adversarial perturbations.
% TODO: maybe add motivation of why robust models are important
%
Adversarial perturbations are carefully crafted but almost imperceptible disturbances that are added to the transmitted signal. These adversarial perturbations can be used as an effective way of jamming wireless communication systems as they require much less energy than normal attacks. Algorithms like FGSM \cite{Goodfellow_Shlens_Szegedy_2015} or PGD \cite{Madry_Makelov_Schmidt_Tsipras_Vladu_2019} can compute such perturbations by solving the following optimization problem:
\begin{equation}
\label{eq:adv_pert}
    \delta_i^* = \argmax_{\delta_i}\Ls(f_{\theta}(x_i + \delta_i), y_i) \quad \text{s.t.} \quad \lVert \delta_i \rVert_{\infty} \leq \varepsilon
\end{equation}
where $\delta_i^*$ is the adversarial perturbation added to the received signal $x_i$, $y_i$ is the one-hot-encoded vector of length K that encodes the modulation used, $\Ls$ is the cross-entropy loss, $f_{\theta}$ is the neural network defined with weights $\theta$, and $\varepsilon$ is a fixed value that constrains the norm of the perturbation to be small and imperceptible.

Some defenses have been proposed to make models more robust against adversarial perturbations. Adversarial training \cite{Madry_Makelov_Schmidt_Tsipras_Vladu_2019} has been shown to be effective in AMC \cite{maroto2021safeamc,manoj2022toward}. Randomized smoothing \cite{kim2021channel,manoj2022toward} and Generative Adversarial Networks (GANs) \cite{wang2022gan} have also been successful in making neural networks more robust. However, \pf{be clear on limitations of the above}. Some works have instead tried to understand why networks are susceptible, and label noise has been pointed to as one of the main causes \cite{sanyal2020benign}. This is consistent with the increase in robustness that is observed when knowledge distillation is used in combination with adversarial training~\cite{goldblum2020adversarially,zi2021revisiting,shao2021and,maroto2022benefits}, which essentially consists in training a student model with labels based on the teacher predictions. \pf{if the above works do not play with KD in AMC, say it clearly} \pf{outline clearly the limitations of other KD works...}

% % Defenses. Relationship with data. Knowledge distillation
% Some defenses have been proposed to make networks more robust, like adversarial training \cite{Madry_Makelov_Schmidt_Tsipras_Vladu_2019}, but it comes at a cost in accuracy and computational time. 

% Our work, what are the main motivations. Contributions.
In this work, we build on the above observations and propose a new data-centric method to make neural networks more accurate and robust to adversarial attacks. In particular, we propose to reduce the label noise \pf{is it formally noise? or uncertainties of some form?} in the training data by distilling the theoretical class probabilities derived from the offline maximum likelihood function estimation. We show that such knowledge distillation permits to achieve better accuracy than models trained with the original labels only. \pf{talk about the robustness aspects, and adversarial training, how is it performed} \pf{talk about robustness results} confirming the effect of label noise in robustness. \pf{recall benefits of the proposal, provide perspectives... how great is that? where do we go from there?}


% \section{Related Work}

% % Maximum likelihood. 
% %   (More details can be found in "Survey of automatic modulation classification techniques").
% Maximum likelihood \cite{huan1995likelihood,dobre2007survey,hameed2009likelihood} is the analytical solution for the AMC task. It computes the likelihood function of the received signal with all possible modulations and estimates the most likely modulation. Despite being Bayes-optimal, because it can be computationally expensive and requires prior knowledge of the channel characteristics, sub-optimal approximations are used in practice \cite{dobre2007survey,Hameed_Dobre_Popescu_2009}.

% Recent approaches. Explain and reference.
% Deep learning \cite{goodfellow2016deep} has been proposed as a better solution for AMC that avoids these shortcomings. Inspired by success in speech recognition, some works \cite{Rajendran_Meert_Giustiniano_Lenders_Pollin_2018,Guo_Jiang_Wu_Zhou_2020} propose architectures based on long short-term memory networks (LSTMs) \cite{Hochreiter_Schmidhuber_1997}. Other works \cite{OShea_Corgan_Clancy_2016,West_OShea_2017,Sadeghi_Larsson_2019} employ convolutional neural networks (CNNs) \cite{Krizhevsky_Sutskever_Hinton_2017} instead, which have been highly successful in computer vision tasks. Particularly, the authors in \cite{OShea_Roy_Clancy_2018} use a model based on the ResNet architecture \cite{Szegedy_Ioffe_Vanhoucke_Alemi_2016}, that outperforms all other CNN architectures. Other works use neural architecture search (NAS) \cite{ahmadi2008modulation,dai2019multi,perenda2021evolutionary} to trade off performance with computational speed. However, all neural networks have common drawbacks: they are black-box models, less interpretable than their classical counterparts, and they are susceptible to adversarial perturbations, compromising the security of the system against malicious attacks.

% Defenses to adversarial attacks
% Adversarial perturbations have been shown to fool neural networks in AMC \cite{Sadeghi_Larsson_2019,maroto2021benefits}. Unlike in other fields, in AMC the power of the perturbation is made dependent on the signal power with the signal-to-perturbation ratio (SPR). Some defenses have been proposed to make models more robust against adversarial perturbations. Adversarial training \cite{Madry_Makelov_Schmidt_Tsipras_Vladu_2019} has been shown to be effective in AMC \cite{maroto2021safeamc,manoj2022toward}. Randomized smoothing \cite{kim2021channel,manoj2022toward} and Generative Adversarial Networks (GANs) \cite{wang2022gan} have also been successful in making neural networks more robust.

% Knowledge distillation
% Knowledge distillation~\cite{hinton2015distilling,romero2014fitnets,zagoruyko2016paying,chebotar2016distilling} consists in training a student model to match the outputs of a teacher model, which has been shown to be effective in transferring performance. However, these approaches do not help the student network in benefitting from the higher adversarial robustness that a teacher network could have~\cite{goldblum2020adversarially}. However, recently, there are works that have proposed alternative loss functions that address this problem~\cite{goldblum2020adversarially,zi2021revisiting,zhu2021reliable,shao2021and,maroto2022benefits}. These solutions encourage and improve the student robustness by matching its output with the teacher outputs on adversarial examples as well as clean examples.



\section{Framework}

\pf{Describe the settings, the different blocks, the AMC problem, the data/label issues in standard training}

% -----

Knowledge distillation~\cite{hinton2015distilling,romero2014fitnets,zagoruyko2016paying,chebotar2016distilling} consists in training a student model to match the outputs of a teacher model, which has been shown to be effective in transferring performance. However, these approaches do not help the student network in benefitting from the higher adversarial robustness that a teacher network could have~\cite{goldblum2020adversarially}. However, recently, there are works that have proposed alternative loss functions that address this problem~\cite{goldblum2020adversarially,zi2021revisiting,zhu2021reliable,shao2021and,maroto2022benefits}. These solutions encourage and improve the student robustness by matching its output with the teacher outputs on adversarial examples as well as clean examples. \pf{to integrate in the part where KD would be introduced as a solution}


%----



Normally, to perform well on AMC, neural networks are trained to infer the modulation used in transmission from the signal received. Thus, the network will be optimized to be as confident and accurate as possible on the training set. However, while enforcing the network to accurately solve the task is feasible for signals with high SNR, on noisier signals typically there is a non-negligible probability that the signal received was generated from a different modulation than the one we are enforcing the model to predict. Such cases are numerous when testing models in the AMC literature, where the signal received could have been generated from any of multiple modulations with similar probability.

While in many other tasks, these probabilities would be difficult or impossible to obtain, in AMC, we can use the maximum likelihood (ML) function to derive the real probabilities. Due to the characteristics of ML, this is only computationally feasible in coherent scenarios, where we have prior knowledge of the channel conditions. Particularly, if we assume the channel is gaussian with variance $\sigma^{2}$, and given the received symbols $r(x)$, where $r$ applies the proper communication filter and downsampling to the received signal. We show in Figure \ref{fig:comm_system} a diagram describing the communication system. We highlight that while the neural network has to process directly what the receptor receives, maximum likelihood processes the symbols of that signal instead. This is possible because we can assume we know the communication filter and upsampling used in the transmitter, which we can invert at the receptor. The ML function when the channel is gaussian is given by the following expression
\begin{equation}
	f_{i}(r(x)) = \dfrac{1}{2\pi \sigma^{2}|M_i|}\prod_{t=1}^{T} \sum_{j=1}^{|M_i|} \exp\left(-\dfrac{\lVert r(x)_t - s_j\rVert^{2}}{2 \sigma^{2}}\right)
\label{eq:ml}
\end{equation}
where $f_{i}$ is the ML function for a given modulation $M_i$ with $|M_i|$ number of states, $T$ is the number of symbols, $r(x)_t$ is the t-th symbol received, and $s_j$ is the symbol that correspond to the state $j$. Given a set of modulations, the probability of a modulation $M_i$ would be $p_{ML}^{(i)}(x) = \log(f_{i}(r(x))) / \sum_i \log(f_{i}(r(x)))$.

\begin{figure}
\begin{tikzpicture}[
	greennode/.style={rectangle, draw=green!60, fill=green!5, very thick, minimum size=5mm},
	graynode/.style={rectangle, draw=gray!60, fill=gray!5, very thick, minimum size=5mm},
	]
	%Nodes
	\node[graynode,text width=1.5cm,text centered](mod){Modulator\\(y)};
	\node[graynode](tf)[minimum height = 1cm][text centered][right=0.25cm of mod]{$r'(x)$};
	\node[graynode](channel)[minimum height = 1cm, right=0.25cm of tf]{Channel};
	\node[graynode](rf)[minimum height = 1cm, right=0.25cm of channel]{$r(x)$};
	\node[graynode](dem)[minimum height = 1cm, text width=1.85cm][text centered][right=0.25cm of rf]{Demodulator\\(pred)};

	\node[greennode](nn)[minimum height = 1cm, text width=1.25cm][text centered][below=0.25cm of channel]{Neural\\Network};
	\node[greennode](ml)[minimum height = 1cm][text centered][below=0.25cm of rf]{ML};
	
	%Lines
	\draw[->] (mod.east) -- (tf.west);
	\draw[->] (tf.east) -- (channel.west);
	\draw[->] (channel.east) -- (rf.west);
	\draw[->] (rf.east) -- (dem.west);
	\draw[->] (channel.south) -- (nn.north);
	\draw[->] (rf.south) -- (ml.north);

	
\end{tikzpicture}
\caption{Simplified diagram of the communication system. The transmitter sends the binary data using the modulator, which converts the data into symbols, and $r'(x)$, which upsamples the signal and passes it through a communication filter (e.g. root raised cosine). The signal passes through the communication channel, which adds noise and distortion to the signal. The receptor does the inverse operation and demodulates the signal based on the neural network prediction. As shown, the signals used by the neural network and ML are slightly different.}
\label{fig:comm_system}
\end{figure}

The reason why ML is not preferred over neural networks is simple: they perform badly in non-coherent scenarios, where the channel or transmission filter parameters are unknown. Moreover, any small deviation from the real channel parameters has a major effect on the ML performance, which discards the possibility of trying to estimate these parameters. Moreover, incorporating the parameter uncertainty in the ML formulation makes it much more costly computationally without being more performant than neural networks.

Based on these limitations, we propose a hybrid approach. We will use a neural network for inference, but we will train it with the probabilities given by maximum likelihood. Because Equation \ref{eq:ml} is limited to gaussian channels, we will remove the Rayleigh/Rician component of the channel when computing the ML probabilities. This is feasible when we consider that we can have full knowledge of the channel conditions by generating the training samples ourselves. Moreover, after training the neural network, ML is no longer needed. Thus allowing our model to be usable under unknown channel conditions, which is typical in real AMC scenarios.

\section{ML distillation for improved accuracy}

\pf{ML estimation (offline), ML distillation ideas, KD-based model description + figure ideally}

\subsection{Maximum likelihood distillation}

Typically in AMC, neural networks try to fit a function that takes as input the received signal data and outputs the modulation used by the transmitter. Thus, the corresponding loss that the model uses to train is given by the standard training loss
\begin{equation}
    \text{ST} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i), y_i)
\end{equation}
where $N$ is the size of the training set.

However, in practice, the neural network is trained with noisy signals where the modulation that was used cannot be inferred so easily. Intuitively, for these signals we would like the outputs of the network to rely on this sense of uncertainty. Thus, with similar principles as knowledge distillation, we propose to match the neural network outputs with the output of ML in the corresponding coherent scenario.
\begin{equation}
    \text{ST\_ML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i), p_{ML}(r(x_i)))
\label{eq:st_ml}
\end{equation}
where $p_{ML}$ is the Maximum Likelihood function, and $r$ is the function that uses the coupled receiver filter and downsamples the signal. Because $r$ and $p_{ML}$ are functions that depend on information that is not known in non-coherent scenarios, we propose to use this loss function only when training the network, where this information can be known.

The main downside of using this function is that, while the probabilities given by ML are optimal in the context of a coherent scenario, they differ from the real probabilities $p^{*}$ that are conditional to the channel and communication filter distributions, $H$. However, our hypothesis, which we test in the following Section, is that training with $p_{ML}$ is going to be a better match to the optimal probabilities $p^{*}$ than the labels $y$ themselves, which enforce full confidence on all samples, no matter how noisy they are. Mathematically, these probabilities are related by the following expression:
\begin{equation}
	p[m|x] =  \sum_i p[m|x,H=h_i] \cdot p[H=h_i|x]
\end{equation}
where $m$ is the vector of all modulations, $h_i$ is one of the possible coherent scenarios where the true coherent scenario is assigned to $h_0$ without loss of generality. Thus, $p[m|x] = p^{*}$ and $p_{ML} = p[m|x,H=h_0]$. Based on this formulation, our model will match better $p^{*}$ when the true communication parameters $H=h_0$ can be easily predicted from x ($p[H=h_0|x] \approx 1$) or when the communication parameters do not affect that much the probabilities ($p[m|x,H=h_i] \approx p_{ML} \; \forall i$).

Additionally, we propose a middle-ground approach, where instead of training the model on the ML probabilities, we use these probabilities to determine if the true label is incorrect. This happens in very noisy scenarios, where the noise added to the signal may change the true class of the signal by pure chance. Intuitively, training on these signals will potentially confuse the network. Thus, we will use standard training loss but removing the label noise by training only on the signals where this does not happen:
\begin{equation}
    \text{ST\_LNR} : \dfrac{1}{|D|}\sum_{i \in D}\Ls(f_{\theta}(x_i), y_i)
\end{equation}
where a training signal $i$ is in the subset $D$ if and only if $\argmax(y_i) = \argmax(p_{ML}(r(x_i)))$.


\section{Robust model construction}

\pf{introduce the problem of robustness, the adversarial training idea, the combination of KD and adversarial training, and provide a clear description of the robust model construction}

While the previous proposals are effective in incorporating the ML information to train the model, they do not address directly the vulnerability of neural networks to adversarial perturbations. One of the most straightforward ways to improve the network robustness is to use the adversarial training loss function
\begin{equation}
    \text{AT} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), y_i)
\end{equation}
where $x_i' = x_i + \delta_i^*$ is a crafted adversarial signal that maximizes the cross-entropy loss of the neural network in the neighborhood of $x_i$.

Analogously to Equation \ref{eq:st_ml}, we propose the following loss to match the model to the ML probabilities
\begin{equation}
    \text{AT\_ML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(x_i')))
\end{equation}
We highlight that, unlike the analogous standard training function, we have to make the assumption that the combination of the channel gaussian noise and the adversarial noise is approximately gaussian with energy $\sigma_F^{2} = \sigma^{2} + \varepsilon^{2}$. This assumption holds when the adversarial perturbation is sufficiently small, which is normally the case during adversarial training.

One way to reduce the effect of this assumption is to instead remove label noise using ML
\begin{equation}
    \text{AT\_LNR} : \dfrac{1}{|D|}\sum_{i \in D}\Ls(f_{\theta}(x_i'), y_i)
\end{equation}
where a training signal $i$ is in the subset $D$ if and only if $\argmax(y_i) = \argmax(p_{ML}(r(x_i')))$. Even if $p_{ML}$ is not strictly correct due to the adversarial perturbation being relatively large, it will tend to remove signals that are already very noisy, thus greatly reducing the chance of label noise affecting adversarial training. Since label noise has a direct impact on the robustness of the network, we expect label noise removal to be particularly effective.

For training with non-gaussian channels, because we remove the Rayleigh/Rician components, we have the drawback that we cannot directly translate the adversarial perturbation added to the neural network to the signal received by ML. For that reason, we have considered the following two solutions: to use the ML probabilities of the uncorrupted signal as follows 
\begin{equation}
    \text{AT\_NML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(g_i))
\label{eq:at_nml}
\end{equation}
and to recompute the adversarial perturbation but for the ML function using the following loss function
\begin{equation}
    \text{AT\_AML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(g_i)'))
	\label{eq:at_aml}
\end{equation}
where $g_i$ is the received signal when the Rayleigh/Rician effects are removed and $r(g_i)'$ is a crafted adversarial signal that maximizes the cross-entropy loss of ML in the neighborhood of $r(g_i)$.

We will show that adversarial perturbations change greatly the probabilities of the received signal, making it desirable to use AT\_AML over AT\_NML.


\section{Experiments}

\pf{make sure that the technical aspects of the communication settings, are clear: non-coherence, type of channel, etc}

\pf{maybe split clearly experiments into clear accuracy results and robustness results}

We propose to evaluate our methodology on scenarios with different levels of non-coherence. This way, we can verify if the probabilities generated by ML in a coherent scenario are useful to train the model even if it is tested on varying channel and transmitter conditions. 

For all the experiments, we train the neural network to distinguish between the following digital modulations: BPSK, QPSK, 8/16/32/64/128/256-PSK, PAM4, 16/32/64/128/256-QAM, GFSK, CPFSK, B-FM, DSB-AM, SSB-AM, and OQPSK \cite{Rajendran_Meert_Giustiniano_Lenders_Pollin_2018,Guo_Jiang_Wu_Zhou_2020}. For the last six modulations, the ML formulation cannot be directly applied, so we use the original labels $y$ on these cases.
For all settings, we consider that the signal sampling frequency is 200KHz. We generate 234000 signals for training and 26000 for testing. The duration of the signal is set to 1024 samples, for consistency with other similar datasets \cite{OShea_West_2016}. For the network, we use a ResNet-based network architecture \cite{OShea_Roy_Clancy_2018}, that while being fast to train has great performance in AMC. We train the network for 100 epochs using SGD optimization with momentum 0.9 and learning rate 0.01, decaying exponentially at a rate of 0.95 per epoch. We use gradient clipping of size 5 and weight decay of 5e-4. When computing the adversarial perturbations for both training and testing the robustness of the network, we use PGD-7 with $\varepsilon=20 \text{dB SPR}$ (signal-to-perturbation ratio).

For the first scenario, we consider a gaussian channel with varying levels of noise ranging from -6 to 18 dB SNR. For the transmitter, we use 8 samples per symbol and a root raised cosine filter with rolloff 0.35. Table \ref{tab:sbasic} proves that the network is much more effective when we remove the label noise, both in the standard and adversarial training scenarios. The increase in robustness is much more significant, which confirms our expectations. However, when using the ML probabilities, we get the biggest increase in performance, which underlines the benefit of distinguishing between uncertain and certain predictions.

For the second scenario, we additionally vary the transmitter settings. We consider either 2, 4, 8, or 16 samples per symbol and the rolloff of the filter can range from 0.15 to 0.45. Table \ref{tab:sawgn2p} shows very similar results as the previous case. However, since there are more parameter configurations, the difference between $p_{ML}$ and $p^{*}$ increases, which shows in the lower increase in performance between LNR and ML methodologies overall.

For the third and final scenario, we use the transmitter settings of the first scenario, but we consider also Rician and Rayleigh channels with AWGN noise. Table \ref{tab:sp0c20} shows smaller improvements compared to the two previous cases. While the probabilities of ML are not discerning well the label noise, which shows in the lack of improvement for the LNR methods, they can still help the network as seen in the ML methods. We highlight that for adversarial training is much more preferable to perturb the signal received by ML before computing the probabilities, due to these probabilities being much more representative of the signal used by the model than the probabilities in the unperturbed point.

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $85.87 \pm 0.02$ & $19.51 \pm 0.25$ \\ 
		ST\_LNR & $86.34 \pm 0.52$ & $24.61 \pm 1.09$ \\ 
		ST\_ML & $\textbf{86.59} \pm 0.32$ & $\textbf{27.30} \pm 0.47$ \\ 
		\hline
		AT & $57.36 \pm 3.12$ & $54.71 \pm 2.67$ \\ 
		AT\_LNR & $64.50 \pm 0.62$ & $58.44 \pm 0.60$ \\ 
		AT\_ML & $\textbf{67.01} \pm 1.04$ & $\textbf{59.44} \pm 0.32$ \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model when only varying the noise settings on a gaussian channel.}
    \label{tab:sbasic}
\end{table}

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $85.78 \pm 0.10$ & $20.56 \pm 1.14$ \\ 
		ST\_LNR & $86.21 \pm 0.08$ & $22.82 \pm 0.88$ \\ 
		ST\_ML & $\textbf{86.58} \pm 0.22$ & $\textbf{24.08} \pm 2.66$ \\
        \hline
		AT & $59.61 \pm 6.44$ & $55.45 \pm 3.64$ \\ 
		AT\_LNR & $64.53 \pm 1.76$ & $\textbf{59.05} \pm 1.42$ \\ 
		AT\_ML & $\textbf{65.06} \pm 1.77$ & $58.72 \pm 0.83$ \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model when varying the noise level, the samples per symbol, and the transmitter communication filter on a gaussian channel.}
    \label{tab:sawgn2p}
\end{table}

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $78.34 \pm 0.02$ & $18.86 \pm 1.83$ \\ 
		ST\_LNR & $78.08 \pm 0.04$ & $18.97 \pm 3.03$ \\ 
		ST\_ML & $\textbf{78.40} \pm 0.22$ & $\textbf{20.00} \pm 1.61$ \\
		\hline
		AT & $50.74 \pm 2.46$ & $\textbf{47.15} \pm 2.53$ \\ 
		AT\_LNR & $48.49 \pm 0.46$ & $45.62 \pm 0.57$ \\  
		AT\_NML & $42.11 \pm 4.66$ & $38.47 \pm 4.88$ \\  
		AT\_AML & $\textbf{54.10} \pm 0.57$ & $\textbf{46.94} \pm 0.17$ \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model when varying the channel properties and the level noise.}
    \label{tab:sp0c20}
\end{table}


\section{Conclusion}

% Future work: ML for Rayleigh/Rician channels. Use in other fields like physics. Test with other KD functions. More models.
We highlight in this work the benefits of incorporating theoretical models like maximum likelihood when training neural networks. We believe this is a crucial step to create networks that are more robust, which ensures higher trust in critical scenarios. We showed that networks are more robust when distilling the probabilities given by these mathematical models, even when they operate under different priors.

For future work, it could be interesting to explore other knowledge distillation losses and to use better ML functions that are adapted to Rayleigh or Rician channels, to improve the results when considering multiple types of channels. Our methodology can also be explored in other research fields like physics, where neural networks are being increasingly preferred over mathematical models \pf{be a bit more precise, or skip this last part...}

\bibliographystyle{IEEEbib}
\bibliography{references}

\end{document}

\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


% Added packages
\usepackage{cite}  
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}

% Latex math commands
\newcommand{\Ls}{\mathcal{L}}
\def\sP{{\mathbb{P}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

%\title{SafeAMC: Adversarial training for robust modulation recognition models}

%\name{Javier Maroto\thanks{This work has been sponsored by armasuisse Science and Technology with the project ROBIN (project code Aramis 047-22).}$^{\star}$ \qquad Gérôme Bovet$^{\dagger}$ \qquad Pascal Frossard$^{\star}$}
  
%\address{$^{\star}$ EPFL, Switzerland \\
%  $^{\dagger}$armasuisse Science\&Technology, Cyber-Defence Campus, Switzerland}
  
\title{ML distillation
\thanks{This work has been sponsored by armasuisse Science and Technology with the project ARNO (project code ???).}
}

\author{\IEEEauthorblockN{Javier Maroto}
\IEEEauthorblockA{\textit{Signal Processing Laboratory (LTS4)} \\ \textit{EPFL, Switzerland}}
\and
\IEEEauthorblockN{Gérôme Bovet}
\IEEEauthorblockA{\textit{armasuisse Science\&Technology} \\
\textit{Cyber-Defence Campus, Switzerland}}
\and
\IEEEauthorblockN{Pascal Frossard}
\IEEEauthorblockA{\textit{Signal Processing Laboratory (LTS4)} \\ \textit{EPFL, Switzerland}}}


\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\begin{IEEEkeywords}
\end{IEEEkeywords}

\section{Introduction}

% 

Deep learning \cite{goodfellow2016deep}

%Adversarial perturbations
Recent studies have highlighted security issues in DNNs models \cite{Szegedy_Zaremba_Sutskever_Bruna_Erhan_Goodfellow_Fergus_2014, moosavi2017universal,Sadeghi_Larsson_2019,Lin_Zhao_2020,Flowers_Buehrer_Headley_2019, maroto2021benefits}. Specifically, those models have been shown to be vulnerable to adversarial examples, which are carefully crafted but almost imperceptible perturbations, namely adversarial perturbations, that are added to a real data sample. For AMC, a perturbation can be crafted by solving the following optimization:
\begin{equation}
\label{eq:adv_pert}
    \delta_i^* = \argmax_{\delta_i}\Ls(f_{\theta}(x_i + \delta_i), y_i) \quad \text{s.t.} \quad \lVert \delta_i \rVert_{\infty} \leq \varepsilon
\end{equation}

\section{Maximum likelihood}

Normally, to perform well on automatic modulation classification (AMC), neural networks are trained to infer the modulation used in transmission from the signal received. Thus, the network will be optimized to be as confident and accurate as possible on the training set. However, while enforcing the network to accurately solve the task is feasible for signals with high SNR, on noisier signals this may no longer the case. The reason is that there could be a non-negligible probability that the signal received was generated from a different modulation than the one we are enforcing the model to predict. In some extreme cases, the noise can even make the task impossible to solve, where the signal received could have been generated from any of multiple modulations with similar probability.

In many other tasks, these probabilities would be difficult or impossible to obtain. However, in AMC, there is an optimal method that gives us these probabilities with perfect accuracy: Maximum Likelihood (ML). Despite its optimal performance, neural networks are still preferred over ML for a simple reason: ML does not perform well when we do not have full knowledge of the channel effects on the signal. In fact, even if we were to estimate the channel, any small deviation from the real channel parameters has a major effect on the ML performance. Moreover, incorporating this uncertainty in the ML formulation makes it computationally unfeasible.

Based on these limitations, we propose a hybrid approach. We will use a neural network for inference, but we will train it with the probabilities given by maximum likelihood. This is feasible when we consider that we can have full knowledge of the channel conditions by generating the training samples ourselves. Moreover, after training the neural network, ML is no longer needed. Thus allowing our model to be usable under unknown channel conditions, which is typical in real AMC scenarios.


\section{Knowledge distillation}

\begin{equation}
    \text{ST} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i), y_i)
\end{equation}
where $N$ is the size of the training set, $\Ls$ is the cross-entropy loss, $f_{\theta}$ is the neural network defined with weights $\theta$ and $x_i$ is the signal received. $y_i$ is a one-hot-encoded vector of length K, that encodes the modulation that was used to generate the signal.

\begin{equation}
    \text{ST\_ML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i), p_{ML}(r(x_i)))
\end{equation}
where $p_{ML}$ is the Maximum Likelihood function, and $r$ is the function that uses the coupled receiver filter and downsamples the signal. Thus, $r$ will be dependent on the filter and samples per symbol used by the transmitter. For this reason, this loss function can only be used when training the network, as this information can be assumed to be known.

\begin{equation}
    \text{ST\_LNR} : \dfrac{1}{|D|}\sum_{i \in D}\Ls(f_{\theta}(x_i), y_i)
\end{equation}
where a training signal $i$ is in the subset $D$ if and only if $\argmax(y_i) = \argmax(p_{ML}(r(x_i)))$. This effectively filters all signals that have label noise. Intuitevely, those signals would be the most corrupted by the noise, to the point where it is more probable that it was generated from a modulation different than the one that was actually used, and potentially confusing the network during training.

\begin{equation}
    \text{AT} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), y_i)
\end{equation}
where $x_i' = x_i + \delta_i^*$ is a crafted adversarial signal that maximizes the cross-entropy loss of the neural network in the neighborhood of $x_i$.

\begin{equation}
    \text{AT\_ML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(x_i')))
\end{equation}

\begin{equation}
    \text{AT\_LNR} : \dfrac{1}{|D|}\sum_{i \in D}\Ls(f_{\theta}(x_i'), y_i)
\end{equation}
where a training signal $i$ is in the subset $D$ if and only if $\argmax(y_i) = \argmax(p_{ML}(r(x_i')))$.

In the case where the channel is not gaussian
\begin{equation}
    \text{AT\_NML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(x_i))
\end{equation}

\begin{equation}
    \text{AT\_AML} : \dfrac{1}{N}\sum_{i}\Ls(f_{\theta}(x_i'), p_{ML}(r(x_i)'))
\end{equation}
where $r(x_i)'$ is a crafted adversarial signal that maximizes the cross-entropy loss of maximum likelihood in the neighborhood of $r(x_i)$.



\section{Experiments}

We propose to evaluate our methodology on scenarios with different levels of non-coherence. This way, we can verify if the probabilities generated by maximum likelihood in a coherent scenario are useful to train the model even if it is tested on varying channel and transmitter conditions. 

For all the experiments the task will be the same. We will train the neural network to be able to distinguish between the following digital modulations: BPSK, QPSK, 8/16/32/64/128/256-PSK, PAM4, 16/32/64/128/256-QAM, GFSK, CPFSK, B-FM, DSB-AM, SSB-AM and OQPSK. This is consistent with other experimental settings used in the field \cite{}. We note that due to implementation difficulties, the last six modulations are ignored by maximum likelihood. Thus, the probability of this classes will be one when used, and zero when not.
For all settings, we consider that the signal sampling frequency is 200KHz. We generate 234000 signals for training, and 26000 for testing. The duration of the signal is set to 1024 samples, for consistency with other similar datasets \cite{}. For the network, we use a ResNet-based network architecture \cite{}. We train the network for 100 epochs using SGD optimization with momentum 0.9 and learning rate 0.01, decaying exponentially at a rate of 0.95 per epoch. We use gradient clipping of size 5 and weight decay of 5e-4.

For the first scenario, we consider a gaussian channel with varying levels of noise ranging from -6 to 18 dB SNR. For the transmitter, we use 8 samples per symbol and a root raised cosine filter with rolloff 0.35. The results of using the different methodologies are shown in Table \ref{tab:sbasic}.

For the second scenario, we additionally vary the transmitter settings. We consider either 2, 4, 8 or 16 samples per symbol and the rolloff of the filter can range from 0.15 to 0.45. The results of using the different methodologies are shown in Table \ref{tab:sawgn2p}.

For the third and final scenario, we use the transmitter settings of the first scenario, but we consider also Rician and Rayleigh channels with AWGN noise. The results of using the different methodologies are shown in Table \ref{tab:sp0c20}. % Maybe specify the parameters used in both channels...

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $85.87 \pm 0.02$ & $19.51 \pm 0.25$ \\ 
		ST\_LNR & $86.34 \pm 0.52$ & $24.61 \pm 1.09$ \\ 
		ST\_ML & $86.59 \pm 0.32$ & $27.30 \pm 0.47$ \\ 
		AT & nan \\ 
		AT\_LNR & nan \\ 
		AT\_ML & nan \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model on the first dataset. The adversarial attacks are crafted using $l_{\infty}$ PGD-7 of 20 dB SPR.}
    \label{tab:sbasic}
\end{table}

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $85.78 \pm 0.10$ & $20.56 \pm 1.14$ \\ 
		ST\_LNR & $86.21 \pm 0.08$ & $22.82 \pm 0.88$ \\ 
		ST\_ML & $\textbf{86.58} \pm 0.22$ & $\textbf{24.08} \pm 2.66$ \\
        \hline
		AT & $59.61 \pm 6.44$ & $55.45 \pm 3.64$ \\ 
		AT\_LNR & $64.53 \pm 1.76$ & $\textbf{59.05} \pm 1.42$ \\ 
		AT\_ML & $\textbf{65.06} \pm 1.77$ & $58.72 \pm 0.83$ \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model when varying the transmission settings on a gaussian channel.}
    \label{tab:sawgn2p}
\end{table}

\begin{table}[htbp]
	\centering
	%\small
	\begin{tabular}{c|cc}
	    Method & Accuracy & Robustness \\
		\hline
		ST & $78.33 \pm 0.03$ & $18.83 \pm 2.59$ \\ 
		ST\_LNR & $78.07 \pm 0.05$ & $17.86 \pm 3.31$ \\ 
		ST\_ML & $78.27 \pm 0.06$ & $20.73 \pm 1.40$ \\ 
		AT & nan \\ 
		AT\_LNR & nan \\ 
		AT\_ML & nan \\ 
    \end{tabular}
    \caption{Accuracy and robustness for the ResNet model on the third dataset. The adversarial attacks are crafted using $l_{\infty}$ PGD-7 of 20 dB SPR.}
    \label{tab:sp0c20}
\end{table}



\bibliographystyle{IEEEbib}
\bibliography{references}

\end{document}

@inproceedings{Lin_Zhao_2020,
  title={Threats of adversarial attacks in DNN-based modulation recognition},
  author={Lin, Yun and Zhao, Haojun and Tu, Ya and Mao, Shiwen and Dou, Zheng},
  booktitle={INFOCOM},
  pages={2469--2478},
  year={2020},
  organization={IEEE}
}

@article{dobre2007survey,
  title={Survey of automatic modulation classification techniques: classical approaches and new trends},
  author={Dobre, Octavia A and Abdi, Ali and Bar-Ness, Yeheskel and Su, Wei},
  journal={IET communications},
  volume={1},
  number={2},
  pages={137--156},
  year={2007},
  publisher={IET}
}

@article{Hameed_Dobre_Popescu_2009,
  title={On the likelihood-based approach to modulation classification},
  author={Hameed, Fahed and Dobre, Octavia A and Popescu, Dimitrie C},
  journal={IEEE Transactions on Wireless Communications},
  volume={8},
  number={12},
  pages={5884--5892},
  year={2009},
  publisher={IEEE}
}

@inproceedings{zhou2013design,
  title={Design and Implementation of Modulation Recognition Algorithm Based on Monitoring Receiver},
  author={Zhou, Peng and An, Qi and Xia, Wei and He, Zi Shu},
  booktitle={Applied Mechanics and Materials},
  volume={411},
  pages={898--902},
  year={2013},
  organization={Trans Tech Publ}
}

@article{huan1995likelihood,
  title={Likelihood methods for MPSK modulation classification},
  author={Huan, Chung-Yu and Polydoros, Andreas},
  journal={IEEE Transactions on Communications},
  volume={43},
  number={2/3/4},
  pages={1493--1504},
  year={1995},
  publisher={IEEE}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{Krizhevsky_Sutskever_Hinton_2017, title={ImageNet classification with deep convolutional neural networks}, volume={60}, ISSN={0001-0782}, DOI={10.1145/3065386}, abstractNote={We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.}, number={6}, journal={Commun. of the ACM}, author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.}, year={2017}, month={May}, pages={84–90} }


@article{Hochreiter_Schmidhuber_1997,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural comput.},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{Szegedy_Ioffe_Vanhoucke_Alemi_2016,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
  booktitle={Thirty-first AAAI conference on artificial intelligence},
  year={2017}
}

@article{OShea_Roy_Clancy_2018,
  title={Over-the-air deep learning based radio signal classification},
  author={O’Shea, Timothy James and Roy, Tamoghna and Clancy, T Charles},
  journal={JSTSP},
  volume={12},
  number={1},
  pages={168--179},
  year={2018},
  publisher={IEEE}
}

 @article{Rajendran_Meert_Giustiniano_Lenders_Pollin_2018, title={Deep Learning Models for Wireless Signal Classification With Distributed Low-Cost Spectrum Sensors}, volume={4}, ISSN={2332-7731}, DOI={10.1109/TCCN.2018.2835460}, abstractNote={This paper looks into the modulation classification problem for a distributed wireless spectrum sensing network. First, a new data-driven model for automatic modulation classification based on long short term memory (LSTM) is proposed. The model learns from the time domain amplitude and phase information of the modulation schemes present in the training data without requiring expert features like higher order cyclic moments. Analyses show that the proposed model yields an average classification accuracy of close to 90\% at varying signal-to-noise ratio conditions ranging from 0 dB to 20 dB. Further, we explore the utility of this LSTM model for a variable symbol rate scenario. We show that a LSTM based model can learn good representations of variable length time domain sequences, which is useful in classifying modulation signals with different symbol rates. The achieved accuracy of 75\% on an input sample length of 64 for which it was not trained, substantiates the representation power of the model. To reduce the data communication overhead from distributed sensors, the feasibility of classification using averaged magnitude spectrum data and on-line classification on the low-cost spectrum sensors are studied. Furthermore, quantized realizations of the proposed models are analyzed for deployment on sensors with low processing power.}, number={3}, journal={TCCN}, author={Rajendran, Sreeraj and Meert, Wannes and Giustiniano, Domenico and Lenders, Vincent and Pollin, Sofie}, year={2018}, month={Sep}, pages={433–445} }
 
 @inproceedings{OShea_Corgan_Clancy_2016,
  title={Convolutional radio modulation recognition networks},
  author={O’Shea, Timothy J and Corgan, Johnathan and Clancy, T Charles},
  booktitle={EANN},
  pages={213--226},
  year={2016},
  organization={Springer}
}

 @inproceedings{West_OShea_2017, title={Deep architectures for modulation recognition}, DOI={10.1109/DySPAN.2017.7920754}, abstractNote={We survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition. Results show that radio modulation recognition is not limited by network depth and further work should focus on improving learned synchronization and equalization. Advances in these areas will likely come from novel architectures designed for these tasks or through novel training methods.}, booktitle={DySPAN}, author={West, N. E. and O’Shea, T.}, year={2017}, month={Mar}, pages={1–6} }

@article{Flowers_Buehrer_Headley_2019,
  title={Evaluating adversarial evasion attacks in the context of wireless communications},
  author={Flowers, Bryse and Buehrer, R Michael and Headley, William C},
  journal={IEEE Transactions on Information Forensics and Security},
  volume={15},
  pages={1102--1113},
  year={2019},
  publisher={IEEE}
}

@article{Guo_Jiang_Wu_Zhou_2020,
  title={Open set modulation recognition based on dual-channel lstm model},
  author={Guo, Youwei and Jiang, Hongyu and Wu, Jing and Zhou, Jie},
  journal={arXiv preprint arXiv:2002.12037},
  year={2020}
}

@inproceedings{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  booktitle={NeurIPS},
  pages={125--136},
  year={2019}
}

@article{Szegedy_Zaremba_Sutskever_Bruna_Erhan_Goodfellow_Fergus_2014,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
 
@inproceedings{moosavi2017universal,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={CVPR},
  pages={1765--1773},
  year={2017}
}

@article{Madry_Makelov_Schmidt_Tsipras_Vladu_2019,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{Cohen_Rosenfeld_Kolter_2019,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={ICML},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@inproceedings{moosavi2019robustness,
  title={Robustness via curvature regularization, and vice versa},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Uesato, Jonathan and Frossard, Pascal},
  booktitle={CVPR},
  pages={9078--9086},
  year={2019}
}

 @article{Cao_Xiao_Yang_Fang_Yang_Liu_Li_2019, title={Adversarial Objects Against LiDAR-Based Autonomous Driving Systems}, url={http://arxiv.org/abs/1907.05418}, abstractNote={Deep neural networks (DNNs) are found to be vulnerable against adversarial examples, which are carefully crafted inputs with a small magnitude of perturbation aiming to induce arbitrarily incorrect predictions. Recent studies show that adversarial examples can pose a threat to real-world security-critical applications: a “physical adversarial Stop Sign” can be synthesized such that the autonomous driving cars will misrecognize it as others (e.g., a speed limit sign). However, these image-space adversarial examples cannot easily alter 3D scans of widely equipped LiDAR or radar on autonomous vehicles. In this paper, we reveal the potential vulnerabilities of LiDAR-based autonomous driving detection systems, by proposing an optimization based approach LiDAR-Adv to generate adversarial objects that can evade the LiDAR-based detection system under various conditions. We first show the vulnerabilities using a blackbox evolution-based algorithm, and then explore how much a strong adversary can do, using our gradient-based approach LiDAR-Adv. We test the generated adversarial objects on the Baidu Apollo autonomous driving platform and show that such physical systems are indeed vulnerable to the proposed attacks. We also 3D-print our adversarial objects and perform physical experiments to illustrate that such vulnerability exists in the real world. Please find more visualizations and results on the anonymous website: https://sites.google.com/view/lidar-adv.}, note={arXiv: 1907.05418}, journal={arXiv:1907.05418 [cs, stat]}, author={Cao, Yulong and Xiao, Chaowei and Yang, Dawei and Fang, Jing and Yang, Ruigang and Liu, Mingyan and Li, Bo}, year={2019}, month={Jul} }

@article{Salman_Li_Razenshteyn_Zhang_Zhang_Bubeck_Yang_2019,
  title={Provably robust deep learning via adversarially trained smoothed classifiers},
  author={Salman, Hadi and Yang, Greg and Li, Jerry and Zhang, Pengchuan and Zhang, Huan and Razenshteyn, Ilya and Bubeck, Sebastien},
  journal={arXiv preprint arXiv:1906.04584},
  year={2019}
}

@article{Jagatap_Chowdhury_Garg_Hegde_2020,
  title={Adversarially robust learning via entropic regularization},
  author={Jagatap, Gauri and Joshi, Ameya and Chowdhury, Animesh Basak and Garg, Siddharth and Hegde, Chinmay},
  journal={arXiv preprint arXiv:2008.12338},
  year={2020}
}

 @article{Sadeghi_Larsson_2019, title={Adversarial Attacks on Deep-Learning Based Radio Signal Classification}, volume={8}, ISSN={2162-2345}, DOI={10.1109/LWC.2018.2867459}, abstractNote={Deep learning (DL), despite its enormous success in many computer vision and language processing applications, is exceedingly vulnerable to adversarial attacks. We consider the use of DL for radio signal (modulation) classification tasks, and present practical methods for the crafting of white-box and universal black-box adversarial attacks in that application. We show that these attacks can considerably reduce the classification performance, with extremely small perturbations of the input. In particular, these attacks are significantly more powerful than classical jamming attacks, which raises significant security and robustness concerns in the use of DL-based algorithms for the wireless physical layer.}, number={1}, journal={IEEE Wireless Commun. Letters}, author={Sadeghi, M. and Larsson, E. G.}, year={2019}, month={Feb}, pages={213–216} }

 @article{Goodfellow_Shlens_Szegedy_2015, title={Explaining and Harnessing Adversarial Examples}, url={http://arxiv.org/abs/1412.6572}, abstractNote={Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks’ vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.}, note={arXiv: 1412.6572}, journal={arXiv:1412.6572 [cs, stat]}, author={Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian}, year={2015}, month={Mar} }

 @article{Kurakin_Goodfellow_Bengio_2017, title={Adversarial examples in the physical world}, url={http://arxiv.org/abs/1607.02533}, abstractNote={Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.}, note={arXiv: 1607.02533}, journal={arXiv:1607.02533 [cs, stat]}, author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy}, year={2017}, month={Feb} }
 
@inproceedings{dong2018boosting,
  title={Boosting adversarial attacks with momentum},
  author={Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9185--9193},
  year={2018}
}

 @article{OShea_West_2016, title={Radio Machine Learning Dataset Generation with GNU Radio}, volume={1}, url={https://pubs.gnuradio.org/index.php/grcon/article/view/11}, abstractNote={This paper surveys emerging applications of Machine Learning (ML) to the Radio Signal Processing domain.  Provides some brief background on enabling methods and discusses some of the potential advancements for the field.  It discusses the critical importance of good datasets for model learning, testing, and evaluation and introduces several public open source synthetic datasets for various radio machine learning tasks.  These are intended to provide a robust common baselines for those working in the field and to provide a benchmark measure against which many techniques can be rapidly evaluated and compared.}, number={11}, journal={Proceedings of the GNU Radio Conference}, author={O’Shea, Timothy J. and West, Nathan}, year={2016}, month={Sep} }

@misc{rml2018_blog,
  title = {DeepSig’s 2018 Data Set},
  howpublished = {\url{https://cyclostationary.blog/2020/09/24/deepsigs-2018-data-set-2018-01-osc-0001_1024x2m-h5-tar-gz/}},
  note = {Accessed: 2020-11-11}
}

@article{Ilyas_Santurkar_Tsipras_Engstrom_Tran_Madry_2019,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1905.02175},
  year={2019}
}

@article{ortiz2020hold,
  title={Hold me tight! Influence of discriminative features on deep network boundaries},
  author={Ortiz-Jimenez, Guillermo and Modas, Apostolos and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},
  journal={arXiv preprint arXiv:2002.06349},
  year={2020}
}
 
 @article{Engstrom_Ilyas_Santurkar_Tsipras_Tran_Madry_2019,
  title={Adversarial robustness as a prior for learned representations},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1906.00945},
  year={2019}
}

@article{andrew1996tanenbaum,
  title={Tanenbaum computer networks},
  author={Andrew, S},
  journal={Computer Networks, Englewood Cliffs},
  pages={141--148},
  year={1996}
}

@inproceedings{Sun_Chen_Shi_Hong_Fu_Sidiropoulos_2017,
  title={Learning to optimize: Training deep neural networks for wireless resource management},
  author={Sun, Haoran and Chen, Xiangyi and Shi, Qingjiang and Hong, Mingyi and Fu, Xiao and Sidiropoulos, Nikos D},
  booktitle={SPAWC},
  pages={1--6},
  year={2017},
  organization={IEEE}
}
 
@article{Chalapathy_Chawla_2019,
  title={Deep learning for anomaly detection: A survey},
  author={Chalapathy, Raghavendra and Chawla, Sanjay},
  journal={arXiv preprint arXiv:1901.03407},
  year={2019}
}


@inproceedings{maroto2021benefits,
  title={On the benefits of robust models in modulation recognition},
  author={Maroto, Javier and Bovet, G{\'e}r{\^o}me and Frossard, Pascal},
  booktitle={Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications III},
  volume={11746},
  pages={1174611},
  year={2021},
  organization={SPIE}
}

@article{sahay2021deep,
  title={A Deep Ensemble-based Wireless Receiver Architecture for Mitigating Adversarial Interference in Automatic Modulation Classification},
  author={Sahay, Rajeev and Brinton, Christopher G and Love, David J},
  journal={arXiv preprint arXiv:2104.03494},
  year={2021}
}

@article{kim2020channel,
  title={Channel-aware adversarial attacks against deep learning-based wireless signal classifiers},
  author={Kim, Brian and Sagduyu, Yalin E and Davaslioglu, Kemal and Erpek, Tugba and Ulukus, Sennur},
  journal={arXiv preprint arXiv:2005.05321},
  year={2020}
}

@inproceedings{kokalj2019mitigation,
  title={Mitigation of adversarial examples in rf deep classifiers utilizing autoencoder pre-training},
  author={Kokalj-Filipovic, Silvija and Miller, Rob and Chang, Nicholas and Lau, Chi Leung},
  booktitle={ICMCIS},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@inproceedings{sahay2021robust,
  title={Robust automatic modulation classification in the presence of adversarial attacks},
  author={Sahay, Rajeev and Love, David J and Brinton, Christopher G},
  booktitle={2021 55th Annual Conference on Information Sciences and Systems (CISS)},
  pages={1--6},
  year={2021},
  organization={IEEE}
}

@inproceedings{xie2008efficient,
  title={An efficient and simple method of MPSK modulation classification},
  author={Xie, Fangjuan and Li, Chisheng and Wan, Guojin},
  booktitle={2008 4th International Conference on Wireless Communications, Networking and Mobile Computing},
  pages={1--3},
  year={2008},
  organization={IEEE}
}

@inproceedings{zhang2017wireless,
  title={Wireless signal classification based on high-order cumulants and machine learning},
  author={Zhang, Yongrong and Wu, Guannan and Wang, Jian and Tang, Qing},
  booktitle={2017 International Conference on Computer Technology, Electronics and Communication (ICCTEC)},
  pages={559--564},
  year={2017},
  organization={IEEE}
}


@article{hameed2009likelihood,
  title={On the likelihood-based approach to modulation classification},
  author={Hameed, Fahed and Dobre, Octavia A and Popescu, Dimitrie C},
  journal={IEEE transactions on wireless communications},
  volume={8},
  number={12},
  pages={5884--5892},
  year={2009},
  publisher={IEEE}
}

@article{sanyal2020benign,
  title={How benign is benign overfitting?},
  author={Sanyal, Amartya and Dokania, Puneet K and Kanade, Varun and Torr, Philip HS},
  journal={arXiv preprint arXiv:2007.04028},
  year={2020}
}

@article{shao2021and,
  title={How and When Adversarial Robustness Transfers in Knowledge Distillation?},
  author={Shao, Rulin and Yi, Jinfeng and Chen, Pin-Yu and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2110.12072},
  year={2021}
}

@inproceedings{goldblum2020adversarially,
  title={Adversarially robust distillation},
  author={Goldblum, Micah and Fowl, Liam and Feizi, Soheil and Goldstein, Tom},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3996--4003},
  year={2020}
}

@inproceedings{zi2021revisiting,
  title={Revisiting adversarial robustness distillation: Robust soft labels make student better},
  author={Zi, Bojia and Zhao, Shihao and Ma, Xingjun and Jiang, Yu-Gang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16443--16452},
  year={2021}
}

@article{maroto2022benefits,
  title={On the benefits of knowledge distillation for adversarial robustness},
  author={Maroto, Javier and Ortiz-Jim{\'e}nez, Guillermo and Frossard, Pascal},
  journal={arXiv preprint arXiv:2203.07159},
  year={2022}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}

@article{zagoruyko2016paying,
  title={Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1612.03928},
  year={2016}
}

@inproceedings{chebotar2016distilling,
  title={Distilling Knowledge from Ensembles of Neural Networks for Speech Recognition.},
  author={Chebotar, Yevgen and Waters, Austin},
  booktitle={Interspeech},
  pages={3439--3443},
  year={2016}
}

@article{zhu2021reliable,
  title={Reliable adversarial distillation with unreliable teachers},
  author={Zhu, Jianing and Yao, Jiangchao and Han, Bo and Zhang, Jingfeng and Liu, Tongliang and Niu, Gang and Zhou, Jingren and Xu, Jianliang and Yang, Hongxia},
  journal={arXiv preprint arXiv:2106.04928},
  year={2021}
}